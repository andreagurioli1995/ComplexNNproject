#print(a)

#trasposta
#training_outputs= np.array([[0,1,1,0]]).T

#moltiplicazione riga per colonna
#pesi_sinaptici+= np.dot(input_layer.T,adjustment)

#random
#np.random.seed(1)
#pesi_sinaptici = 2*np.random.random((3,1))-1




#alternativa alla funzione di sigmund:
# rectified linear function
#def rectified(x):
#	return max(0.0, x)
#"""https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/"""
